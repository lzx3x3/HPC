{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Performance Metrics & First Week Flop/s\n",
    "\n",
    "This assignment has some questions that you need to answer with text, and some code that you need to write.\n",
    "\n",
    "You should put all of you textual answers in this notebook: `Insert->Insert Cell Below` to create a new cell below\n",
    "the question, and `Cell->Cell Type->Markdown` to make it a cell for entering text.\n",
    "\n",
    "You will test your code on the compute nodes of pace-ice, and that it also where we will evaluate it.\n",
    "Please complete the text portions when you are logged into a head node working locally, and leave the compute nodes for when you actually need them.\n",
    "\n",
    "**Due: Tuesday, September 2, 9:30 am**\n",
    "\n",
    "**Total: 10 pts + 2 bonus pts (1 for working on a node with GPUs, 1 for optimizing the flop/s code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "In class we talked about the _strong-scaling efficiency_ of a parallel algorithm / machine pair: $H_f(P) = T_f(1) / (P T_f(P))$.\n",
    "\n",
    "We then talked about the _weak-scaling efficiency_ of algorithm $f$ that can be applied to different problem sizes $N$: $E_f(N,P) = T_f(N/P,1) / T_f(N,P)$.\n",
    "\n",
    "The question came up of how they are related to each other.\n",
    "\n",
    "First, the notion of strong scaling doesn't have a concept of problem size, so let's add it: let's define\n",
    "\n",
    "$$H_f(N,P) = T_f(N,1) / (P T_f(N,P)).$$\n",
    "\n",
    "This is simply strong-scaling efficiency for each problem instance individually.\n",
    "\n",
    "**Question 1 (1 pt):** Show that the relative order of strong and weak scaling efficiency (Whether $H_f(N,P) < E_f(N,P)$ or $E_f(N,P) < H_f(N,P)$) can be related to the efficiency of the serial algorithm, that is, whether $T_f(N,1)$ as a function of $N$ exhibits superlinear or sublinear behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "$$H_f(N,P) = T_f(N,1) / (P T_f(N,P)).$$\n",
    "$$E_f(N,P) = T_f(N/P,1) / T_f(N,P)$$\n",
    "**Then**\n",
    "$$\\frac{H_f(N,P)}{E_f(N,P)} = \\frac{T_f(N,1) / (P T_f(N,P))}{T_f(N/P,1) / T_f(N,P)}$$\n",
    "**To**\n",
    "$$\\frac{H_f(N,P)}{E_f(N,P)} = \\frac{T_f(N,1)}{P*T_f(N/P,1)}$$\n",
    "**Since**\n",
    "$$P*T_f(N/P,1) < = T_f(N,1)$$\n",
    "**Thus**\n",
    "$$\\frac{H_f(N,P)}{E_f(N,P)}>=1$$\n",
    "which means the **superlinear**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PACE-ICE\n",
    "\n",
    "**Head node exercise 1 (1 pt):** What command should you run from a head node to see a list of all the compute nodes in `coc-ice` and their availability? [Resource for this question: the [orientation slides](http://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t** NEW FEATURE : add '-s' to pace-check-queue to list \n",
      "\t** scheduler features for each node\n",
      "\n",
      "=== coc-ice Queue Summary: ====\n",
      "\tLast Update                            : 09/01/2019 18:45:02\n",
      "\tNumber of Nodes (Accepting Jobs/Total) : 48/49 (97.96%)\n",
      "\tNumber of Cores (Used/Total)           : 2/916 ( 0.22%)\n",
      "\tAmount of Memory (Used/Total) (MB)     : 123561/8105865 ( 1.52%)\n",
      "=================================================================================\n",
      "  Hostname       tasks/np Cpu%  loadav%  used/totmem(MB)   Mem%   Accepting Jobs? \n",
      "=================================================================================\n",
      "rich133-h35-15-r   1/28    3.6     1.0      3044/131126     2.3    Yes (free)             \n",
      "rich133-h35-16-l   0/28    0.0     1.2      2912/131126     2.2    Yes (free)             \n",
      "rich133-h35-16-r   0/28    0.0     0.5      3074/131126     2.3    Yes (free)             \n",
      "rich133-h35-17-l   0/28    0.0     0.7      5062/518966     1.0    Yes (free)             \n",
      "rich133-h35-17-r   0/28    0.0     0.5      5068/518966     1.0    Yes (free)             \n",
      "rich133-h35-18-l   0/28    0.0     0.4      5234/518966     1.0    Yes (free)             \n",
      "rich133-h35-18-r   0/28    0.0     0.8      5042/518966     1.0    Yes (free)             \n",
      "rich133-k33-17     0/8     0.0     0.4      3602/260408     1.4    Yes (free)             \n",
      "rich133-k40-17     0/8     0.0     8.2      2835/131128     2.2    Yes (free)             \n",
      "rich133-k40-18     0/8     0.0     0.8      2807/131128     2.1    Yes (free)             \n",
      "rich133-k40-20-l   0/28    0.0     0.8      3155/131126     2.4    Yes (free)             \n",
      "rich133-k40-20-r   0/28    0.0     0.6      2999/131126     2.3    Yes (free)             \n",
      "rich133-k40-21-l   0/28    0.0     1.2      2799/131126     2.1    Yes (free)             \n",
      "rich133-k40-21-r   0/28    0.0     0.9      2878/131126     2.2    Yes (free)             \n",
      "rich133-k40-22-l   0/28    0.0     1.7      2868/131126     2.2    Yes (free)             \n",
      "rich133-k40-22-r   0/28    0.0     1.0      3063/131126     2.3    Yes (free)             \n",
      "rich133-k40-23-l   0/28    0.0     0.9      3034/131126     2.3    Yes (free)             \n",
      "rich133-k40-23-r   0/28    0.0     0.3      2877/131126     2.2    Yes (free)             \n",
      "rich133-k40-24-l   0/28    0.0     1.0      2868/131126     2.2    Yes (free)             \n",
      "rich133-k40-24-r   0/28    0.0     0.5      2856/131126     2.2    Yes (free)             \n",
      "rich133-k40-25-l   0/28    0.0     0.6      2930/131126     2.2    Yes (free)             \n",
      "rich133-k40-25-r   0/28    0.0     1.1      2818/131126     2.1    Yes (free)             \n",
      "rich133-k40-26-l   0/28    0.0     0.3      3125/131126     2.4    Yes (free)             \n",
      "rich133-k40-26-r   0/28    0.0     0.5      2850/131126     2.2    Yes (free)             \n",
      "rich133-k40-27-l   0/28    0.0     1.1      3100/131126     2.4    Yes (free)             \n",
      "rich133-k40-27-r   0/28    0.0     0.5      3013/131126     2.3    Yes (free)             \n",
      "rich133-k40-29     0/8     0.0     0.2      2993/131128     2.3    Yes (free)             \n",
      "rich133-k40-30     0/8     0.0     0.9      2786/131128     2.1    Yes (free)             \n",
      "rich133-s30-10     0/12    0.0     2.2      1297/131128     1.0    Yes (free)             \n",
      "rich133-s30-11     0/12    0.0     1.2      1464/131128     1.1    Yes (free)             \n",
      "rich133-s30-12     0/12    0.0     1.3      1640/131128     1.3    Yes (free)             \n",
      "rich133-s30-13     0/12    0.0     2.2      1569/131128     1.2    Yes (free)             \n",
      "rich133-s30-14     0/12    0.0     0.2      1495/131128     1.1    Yes (free)             \n",
      "rich133-s30-15     0/12    0.0     2.1      1492/131128     1.1    Yes (free)             \n",
      "rich133-s30-16     0/12    0.0     1.2      1648/131128     1.3    Yes (free)             \n",
      "rich133-s30-17     0/12    0.0     0.9      1476/131128     1.1    Yes (free)             \n",
      "rich133-s30-18     0/12    0.0     1.0      1483/131128     1.1    Yes (free)             \n",
      "rich133-s30-19     0/12    0.0     1.1      1656/131128     1.3    Yes (free)             \n",
      "rich133-s30-20     0/24    0.0     0.2      1139/131127     0.9    No  (node down or offline) \n",
      "rich133-s30-21     1/12    8.3     0.5      1778/131128     1.4    Yes (free)             \n",
      "rich133-s30-22     0/12    0.0     0.6      1457/131128     1.1    Yes (free)             \n",
      "rich133-s42-21     0/8     0.0     2.9      1535/131128     1.2    Yes (free)             \n",
      "rich133-s42-22     0/8     0.0     0.1      1450/131128     1.1    Yes (free)             \n",
      "rich133-s42-23     0/8     0.0     3.4      1606/131128     1.2    Yes (free)             \n",
      "rich133-s42-24     0/8     0.0     1.8      1587/131128     1.2    Yes (free)             \n",
      "rich133-s42-25     0/8     0.0     1.1      1607/131128     1.2    Yes (free)             \n",
      "rich133-s42-26     0/8     0.0     0.1      1449/131128     1.1    Yes (free)             \n",
      "rich133-s42-27     0/8     0.0     0.0      1591/131128     1.2    Yes (free)             \n",
      "rich133-s42-28     0/8     0.0     0.0      1450/131128     1.1    Yes (free)             \n"
     ]
    }
   ],
   "source": [
    "pace-check-queue coc-ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out: open up this notebook on a head node and compare the list you get to the [orientation slides](http://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf).  You'll see that it has grown, and they haven't updated the orientation slides.  We'll just have to find out what all these new nodes are for ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A word on running jupyter on pace-ice:\n",
    "\n",
    "As we discussed in class, screen refresh can be a bit laggy if you try to run a jupyter notebook through a browser opened on the head node or a compute node.  See the [guide](../../notes/logistics/compute-node-notebook.ipynb) in the notes for instructions on runnin the jupyter server on the compute nodes and the browser on your own computer.  You don't have to work directly in the notebook: you can work on you answers in the terminal, and then paste them into the notebook, as long as you're confident that they are correct.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Head node exercise 2 (1 pt):** From the output of the above answer, you can probably see that we have a few different types of nodes to work with.  Fill in the blanks in the list below, describing the _properties_ of the different types. [Command line tools you might want to use: `qnodes`, `grep`, `sort`]\n",
    "\n",
    "1. #__ nodes with __ CPU core(s) and no GPUs\n",
    "2. #__ nodes with __ CPU core(s) and #__ GPU(s) of type NVIDIA Tesla ____.\n",
    "3. #__ nodes with __ CPU core(s) and #__ GPU(s) of type NVIDIA Tesla ____ (this group includes `rich133-s42-21.pace.gatech.edu`, even though that the type of GPU is not listed for this node)\n",
    "5. One node (`rich133-s30-20.pace.gatech.edu`) with __ CPU core(s) (currently offline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "1. $23$ nodes with $28$ CPU core(s) and no GPUs.\n",
    "2. $12$ nodes with $12$ CPU core(s) and $2$ GPU(s) of type NVIDIA Tesla K40.\n",
    "3. $12$ nodes with $8$ CPU core(s) and $1$ GPU(s) of type NVIDIA Tesla P100. And $1$ node(`rich133-s42-21`) with $8$ CPU core(s) and $2$ GPU(s) of type NVIDIA Tesla P100.\n",
    "4. One node (`rich133-s30-20.pace.gatech.edu`) with $24$ CPU core(s) and with $2$ GPUs of type NVIDIA Tesla K40 . (currently offline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rich133-h35-15-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-h35-16-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-h35-16-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-h35-17-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-h35-17-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-h35-18-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-h35-18-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k33-17.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 2\n",
      "rich133-k40-17.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-k40-18.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-k40-20-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-20-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-21-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-21-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-22-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-22-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-23-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-23-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-24-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-24-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-25-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-25-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-26-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-26-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-27-l.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-27-r.pace.gatech.edu\n",
      "     np = 28\n",
      "rich133-k40-29.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-k40-30.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s30-10.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-11.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-12.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-13.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-14.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-15.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-16.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-17.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-18.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-19.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-20.pace.gatech.edu\n",
      "     np = 24\n",
      "     gpus = 2\n",
      "rich133-s30-21.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s30-22.pace.gatech.edu\n",
      "     np = 12\n",
      "     gpus = 2\n",
      "rich133-s42-21.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-22.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-23.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-24.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-25.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-26.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-27.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n",
      "rich133-s42-28.pace.gatech.edu\n",
      "     np = 8\n",
      "     gpus = 1\n"
     ]
    }
   ],
   "source": [
    "Nodes=\"$(qnodes|grep '^rich')\"\n",
    "for i in $Nodes; do\n",
    "    echo $i\n",
    "    qnodes $i|grep np\n",
    "    qnodes $i|grep gpus\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Nodes CPU, CPU cores count:\n",
      "     12      np = 12\n",
      "      1      np = 24\n",
      "     23      np = 28\n",
      "     13      np = 8\n",
      "All Nodes with GPU, GPU count: \n",
      "     12      gpus = 1\n",
      "     14      gpus = 2\n",
      "2 GPUs with Tesla P100 count total:\n",
      "1\n",
      "2 GPUs with Tesla K40m count total:\n",
      "13\n",
      "Access rich133-s30-20.pace.gatech.edu info:\n",
      "rich133-s30-20.pace.gatech.edu\n",
      "     state = down,offline\n",
      "     power_state = Running\n",
      "     np = 24\n",
      "     properties = core24,mhz2400,ib,ibQDR,localdisk,nvidiagpu,teslak40,ssd,5-2620v3,intel,rhel6\n",
      "     ntype = cluster\n",
      "     status = rectime=1566377608,macaddr=40:8d:5c:65:77:74,cpuclock=Fixed,varattr=,jobs=,state=free,size=87755940kb:88117536kb,netload=240088208,gres=,message=ERROR Health check failed:  [pace_mce] /var/log/mcelog has at least one uncorrectable error,loadave=0.05,ncpus=12,physmem=132177880kb,availmem=133108192kb,totmem=134275028kb,idletime=224,nusers=0,nsessions=0,uname=Linux rich133-s30-20.pace.gatech.edu 2.6.32-573.12.1.el6.x86_64 #1 SMP Mon Nov 23 12:55:32 EST 2015 x86_64,opsys=RHEL6.7\n",
      "     note = 06/05/19:ksuda3:Down, offline to diagnose  - ERROR Health check failed:  [pace_mce] /var/log/mcelog has at least one uncorrectable error - ERROR Health check failed:  [pace_mce] /var/log/mcelog has at least one uncorrectable error - ERROR Health check failed:  [pace_mce] /var/log/mcelog has at least one uncorrectable error\n",
      "\n",
      "     mom_service_port = 15002\n",
      "     mom_manager_port = 15003\n",
      "     gpus = 2\n",
      "     gpu_status = gpu[1]=gpu_id=00000000:81:00.0;gpu_product_name=Tesla K40m;gpu_display=Disabled;gpu_pci_device_id=102310DE;gpu_pci_location_id=00000000:81:00.0;gpu_fan_speed=N/A;gpu_mode=Exclusive_Process;gpu_state=Unallocated;gpu_utilization=0 %;gpu_memory_utilization=0 %;gpu_ecc_mode=Enabled;gpu_single_bit_ecc_errors=0;gpu_double_bit_ecc_errors=0;gpu_temperature=31 C,gpu[0]=gpu_id=00000000:02:00.0;gpu_product_name=Tesla K40m;gpu_display=Disabled;gpu_pci_device_id=102310DE;gpu_pci_location_id=00000000:02:00.0;gpu_fan_speed=N/A;gpu_mode=Exclusive_Process;gpu_state=Unallocated;gpu_utilization=0 %;gpu_memory_utilization=0 %;gpu_ecc_mode=Enabled;gpu_single_bit_ecc_errors=0;gpu_double_bit_ecc_errors=0;gpu_temperature=21 C,driver_ver=390.30,timestamp=Wed Aug 21 04:53:28 2019\n",
      "\n",
      "rich133-s42-21.pace.gatech.edu\n",
      "     state = free\n",
      "     power_state = Running\n",
      "     np = 8\n",
      "     properties = core8,mhz2600,ib,ibQDR,localdisk,ssd,5-2623v4,intel,rhel6\n",
      "     ntype = cluster\n",
      "     status = rectime=1567378886,macaddr=1c:1b:0d:b4:10:14,cpuclock=Fixed,varattr=,jobs=,state=free,size=108960584kb:109271976kb,netload=4108080140,gres=,loadave=0.05,ncpus=8,physmem=132178848kb,availmem=132693496kb,totmem=134275996kb,idletime=888573,nusers=0,nsessions=0,uname=Linux rich133-s42-21.pace.gatech.edu 2.6.32-573.12.1.el6.x86_64 #1 SMP Mon Nov 23 12:55:32 EST 2015 x86_64,opsys=RHEL6.7\n",
      "     mom_service_port = 15002\n",
      "     mom_manager_port = 15003\n",
      "     gpus = 1\n",
      "     gpu_status = gpu[0]=gpu_id=00000000:02:00.0;gpu_product_name=Tesla P100-PCIE-16GB;gpu_display=Enabled;gpu_pci_device_id=15F810DE;gpu_pci_location_id=00000000:02:00.0;gpu_fan_speed=N/A;gpu_mode=Default;gpu_state=Unallocated;gpu_utilization=0 %;gpu_memory_utilization=0 %;gpu_ecc_mode=Enabled;gpu_single_bit_ecc_errors=0;gpu_double_bit_ecc_errors=0;gpu_temperature=27 C,driver_ver=390.30,timestamp=Sun Sep  1 19:01:25 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printf \"All Nodes CPU, CPU cores count:\\n\"\n",
    "qnodes|grep \"np\"|sort|uniq -c\n",
    "printf \"All Nodes with GPU, GPU count: \\n\"\n",
    "qnodes|grep gpus|sort|uniq -c\n",
    "printf \"2 GPUs with Tesla P100 count total:\\n\"\n",
    "qnodes|grep \"gpu\\[0]\"|grep \"gpu\\[1]\"|grep 'P100'|sort|uniq -c|awk '{s+=$1} END {print s}'\n",
    "printf \"2 GPUs with Tesla K40m count total:\\n\"\n",
    "qnodes|grep \"gpu\\[0]\"|grep \"gpu\\[1]\"|grep 'K40m'|sort|uniq -c|awk '{s+=$1} END {print s}'\n",
    "printf \"Access rich133-s30-20.pace.gatech.edu info:\\n\"\n",
    "qnodes rich133-s30-20.pace.gatech.edu \n",
    "qnodes rich133-s42-21.pace.gatech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Head node exercise 3 (1 pt):** For the next questions, I need you to log in to compute nodes to find out about them, but you need to be able to specify which type of compute nodes you are accessing.\n",
    "\n",
    "For each of the types of nodes 1, 2, and 3 in the question above, give me a `qsub` command to start a `jupyter_notebook_script.sh` job on that type of node, with the following requirements:\n",
    "\n",
    "* The job should give you exclusive access to one node and all its cores and devices.\n",
    "* The job should begin in the CSE6230 directory.\n",
    "* The job should end after 30 minutes.\n",
    "\n",
    "[Resources: [compute-node-notebook.ipynb](../../notes/logistics/compute-node-notebook.ipynb), [orientation slides](http://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106309.ice-sched.pace.gatech.edu\n"
     ]
    }
   ],
   "source": [
    "# put the qsub command for type 1 in this cell\n",
    "qsub -l nodes=rich133-h35-18-l.pace.gatech.edu:ppn=28,walltime=00:30:00 $CSE6230_DIR/utils/jupyter_notebook_job.sh -w $CSE6230_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106245.ice-sched.pace.gatech.edu\n"
     ]
    }
   ],
   "source": [
    "# put the qsub command for type 2 in this cell\n",
    "qsub -l nodes=rich133-s30-12.pace.gatech.edu:ppn=12:gpus=2,walltime=00:30:00 $CSE6230_DIR/utils/jupyter_notebook_job.sh -w $CSE6230_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106209.ice-sched.pace.gatech.edu\n"
     ]
    }
   ],
   "source": [
    "# put the qsub command for type 3 in this cell\n",
    "qsub -l nodes=rich133-s42-23.pace.gatech.edu:ppn=8:gpus=1,walltime=00:30:00  $CSE6230_DIR/utils/jupyter_notebook_job.sh -w $CSE6230_DIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What have we got to work with?\n",
    "\n",
    "Now, we need to switch from a notebook running on the head node to one running on a compue node, so `File->Save and Checkpoint` this notebook and `File->Close and Halt` it.  (Now would also be a good time to `git add` and `git commit` changes to this file.)  Use one of your ineractive job scripts to connect to a compute node and run the notebook there.\n",
    "See you on the other side!\n",
    "\n",
    "---\n",
    "\n",
    "Okay, you're running on the compute node.\n",
    "\n",
    "**Compute node exercise 1 (2 pt):** Using bash scripting (`awk`, `grep`, `sed`) or any other tool you like (you could, e.g., write a python script in a separate file and call it, as long as you `git add` it), set the variables in the cell below so that the printout that follows is correct.  You script should be correct on any type of compute node.\n",
    "\n",
    "Resources: the file `/proc/cpuinfo`, the utility `nvidia-smi`; if you are very new to using a shell command line and the utilities that go with it in linux, please look at the [training slides on Linux](https://pace.gatech.edu/training) from PACE.\n",
    "\n",
    "Note: when you run a command in backticks, you can assign its value to a variable like\n",
    "\n",
    "```bash\n",
    "MY_FILES=`ls -al`\n",
    "```\n",
    "\n",
    "Also note: when ever you encounter a new program or utility `AAA` that you've never used before, `man AAA` or `AAA --help` are the first places to go if you want to know what different command line flags do.\n",
    "\n",
    "Some [one-liners](https://en.wikipedia.org/wiki/One-liner_program) that you may find useful:\n",
    "\n",
    "* `grep -P -m 1 -o -e \"(?<=XXX\\s: ).*\" YYY`: look in file `YYY` for the string \"XXX   : \" (with an arbitrary number of spaces between `XXX` and `:`) and print what comes after that on the line\n",
    "* `wc -l YYY` counts the number of lines in file `YYY`\n",
    "* most command line utilities that read files can also read the output of a previous command with a pipe `|`, for example to count the number of files in a directory:\n",
    "\n",
    "```bash\n",
    "ls -al | wc -l\n",
    "```\n",
    "\n",
    "* `grep -c \"ZZZ\" YYY` count the number of times the string `ZZZ` occurs in file `YYY`\n",
    "* Nodes without GPUs won't have the `nvidia-smi` utility.  You can tell when a utility is unavailable if `which AAA` returns an error.  If you want to write a one-liner that only runs command `AAA` when `nvidia-smi` when it's available, you can do that like this:\n",
    "\n",
    "```bash\n",
    "(which nvidia-smi &> /dev/null) && (AAA)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_NAME=`cat /proc/cpuinfo| grep 'model name'|uniq | grep -P -m 1 -o -e \"(?<=model name\\s: ).*\"`\n",
    "CORE_COUNT=`cat /proc/cpuinfo |grep 'model name'|wc -l`\n",
    "GPU_NAME=`nvidia-smi -q|grep 'Product Name'|uniq|grep -o \"Tesla.*\"`\n",
    "GPU_COUNT=`nvidia-smi -q|grep 'Product Name'|wc -l`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This nodes has 28 cores: its architecture is (Manufacturer, Product Id) Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz\n",
      "This node has no GPUs\n"
     ]
    }
   ],
   "source": [
    "echo \"This nodes has ${CORE_COUNT} cores: its architecture is (Manufacturer, Product Id) ${CPU_NAME}\"\n",
    "if [[ ! $GPU_COUNT || $GPU_COUNT == 0 ]] ;  then\n",
    "    echo \"This node has no GPUs\"\n",
    "else\n",
    "    echo \"This node has ${GPU_COUNT} GPUs: its/their architecture is (Manufacturer, Product Id) ${GPU_NAME}\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute node exercise 2 (1 pt):** After you have logged out of the compute node, use whatever resources published on the web you can find to estimate the peak _single precision_ (aka FP32) flop/s of this node (you only need to do this step for one of the types of nodes, not all of them).\n",
    "\n",
    "[Resources: [ark.intel.com](https://ark.intel.com), [wikipedia:FLOPS](https://en.wikipedia.org/wiki/FLOPS), [wikichip](https://en.wikichip.org), our notebook on [processors](../../notes/processors/processors-alone.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU(s):                28\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    14\n",
      "Socket(s):             2\n"
     ]
    }
   ],
   "source": [
    "lscpu | grep -E '^Thread|^Core|^Socket|^CPU\\('"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen node type **1** .  The peak flop/s for this node is **2150.4** gigaflop/s.  Here is how I calculated that:\n",
    "$$FLOPS = sockets * \\frac{cores}{socket} *\\frac{cycles}{second}*\\frac{FLOPS}{cycle}$$\n",
    "(source wikipedia:FLOPS)\n",
    "$$Peak Flop = 2*14*2.4Ghz*32FLOPs/cycle$$\n",
    "$$Peak Flop = 2150.4 GFLOPS/s$$\n",
    "\n",
    "\n",
    "(calculation goes here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flop/s fever\n",
    "\n",
    "We've got to scratch that itch: we just want to go fast.  Okay, let's get it out of our system, and we'll look at more practical computations in future assignments.\n",
    "\n",
    "You should choose one of the node types for this task.  Because this is more complex if multiple devices are involved\n",
    "**1 bonus point** is earned for choosing a node with GPUs.\n",
    "\n",
    "**Compute node exercise 3 (2 pts):** The command below will compile and runs essentially the following computation:\n",
    "\n",
    "```C\n",
    "for (i = 0; i < Nh; i++) { /* this loop will run on the \"host\" (CPUs) */\n",
    "  for (j = 0; j < T; j++) {\n",
    "    ah[i] = ah[i] * b + c;\n",
    "  }\n",
    "}\n",
    "\n",
    "for (i = 0; i < Nd; i++) { /* this loop will run on the \"device\" (GPUs) */\n",
    "  for (j = 0; j < T; j++) {\n",
    "    ad[i] = ad[i] * b + c;\n",
    "  }\n",
    "}\n",
    "```\n",
    "And it will report the flop/s for the whole calculation.\n",
    "\n",
    "`Nh` array entries will be on the host and `Nd` entries will be on each of the devices.  Try to find values of `Nh`, `Nd`, and `T`, and (optionally) compiler optimization flags that give you the highest flop/s.  Things to consider:\n",
    "\n",
    "- Try to make your whole computation run for about a second.\n",
    "- The time reported is the maximum time for any device: if one sits idle while the other finishes, it will rob you of flop/s.\n",
    "- I suggest looking at one type of device at a time: set one of `Nh` or `Nd` to zero.  Once you've found your best flop/s for that device, optimize the other, and then try to strike a balance.\n",
    "- Experiment with the merits of putting more weight on `Nh` and `Nd` vs more weight on `T`.\n",
    "  Try to use **Little's Law** to make sure that you have enough parallelism to keep the pipelines filled.\n",
    "- You can also choose to pass the option `Bs=X` to control the thread block size for the GPU, where `X` is a power of 2 between 64 and 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dentry cache hash table entries: 67108864 (order: 17, 536870912 bytes)\n",
      "Inode-cache hash table entries: 33554432 (order: 16, 268435456 bytes)\n",
      "Mount-cache hash table entries: 256\n",
      "PCI: old code would have set cacheline size to 32 bytes, but clflush_size = 64\n",
      "PCI: pci_cache_line_size set to 64 bytes\n",
      "IP route cache hash table entries: 524288 (order: 10, 4194304 bytes)\n",
      "Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\n",
      "ehci_hcd 0000:00:1a.0: cache line size of 64 is not supported\n",
      "ehci_hcd 0000:00:1d.0: cache line size of 64 is not supported\n",
      "xhci_hcd 0000:00:14.0: cache line size of 64 is not supported\n",
      "sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n",
      "CacheFiles: Can't set xattr on cache [451881] (err 95)\n"
     ]
    }
   ],
   "source": [
    "dmesg | grep cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                28\n",
      "On-line CPU(s) list:   0-27\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    14\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 79\n",
      "Stepping:              1\n",
      "CPU MHz:               2399.777\n",
      "BogoMIPS:              4799.30\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              35840K\n",
      "NUMA node0 CPU(s):     0-13\n",
      "NUMA node1 CPU(s):     14-27\n"
     ]
    }
   ],
   "source": [
    "lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Trials:***\n",
    "Since Only CPU is used for type 1, I denote Nd=0, and start Nh = 256, each time I double the Nh, and monitor the flop/s rate, I found a relative high peak value happened at Nh=8388608,T=12.  Result a flop/s rate at 6.6-6.9 e+11 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.o *.optrpt *.so fma_prof fma_prof_opt\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_prof.o fma_prof.c\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_omp.o fma_omp.c\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_loop_host.o fma_loop_host.c\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O3 -dc -o fma_cuda.o fma_cuda.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O3 -dc -o fma_loop_dev.o fma_loop_dev.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -dlink  fma_cuda.o fma_loop_dev.o -o fma_cuda_link.o\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "icpc -qopenmp -shared -Wl,-soname,libfma_cuda.so -o libfma_cuda.so fma_cuda_link.o fma_cuda.o fma_loop_dev.o -L/usr/local/pacerepov1/cuda/8.0.44/lib64 -Wl,-rpath,/usr/local/pacerepov1/cuda/8.0.44/lib64 -lcudart\n",
      "icpc -qopenmp -o fma_prof fma_prof.o fma_omp.o fma_loop_host.o libfma_cuda.so -Wl,-rpath,.\n",
      "OMP_PROC_BIND=spread OMP_NUM_THREADS=28  ./fma_prof 8388608 0 -1 -1 12 0.5 3.0\n",
      "[./fma_prof] Nh = 8388608, Nd = 0, T = 12, default block size\n",
      "[./fma_prof]: 2.989769e-04 elapsed seconds\n",
      "[./fma_prof]: 201326592 flops executed\n",
      "[./fma_prof]: 6.733851e+11 flop/s\n"
     ]
    }
   ],
   "source": [
    "make clean\n",
    "\n",
    "make run_fma_prof Nh=8388608 Nd=0 T=12 COPTFLAGS='-O3 -xHost' CUOPTFLAGS='-O3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Node Exercise 4 (Bonus 1 pt):** Now let's see if we can make any transformations to the code to make a difference.\n",
    "\n",
    "We will run the same program, but with fused multiply add loops that you have tried to optimize.  You should edit the files\n",
    "`fma_loop_host_opt.cu` and/or `fma_loop_dev_opt.c`: they start out exactly the same as the reference implementations used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,22c21,22\n",
      "<   for (int i = 0; i < N; i++) {\n",
      "<     for (int j = 0; j < T; j++) {\n",
      "---\n",
      ">   #pragma unroll(12)\n",
      ">   for (int i = 0; i < N; i+=8) {\n",
      "24c24,35\n",
      "<     }\n",
      "---\n",
      ">       a[i+1] = a[i+1]*b + c;\n",
      ">       a[i+2] = a[i+2]*b + c;\n",
      ">       a[i+3] = a[i+3]*b + c;\n",
      ">       a[i+4] = a[i+4] * b + c;\n",
      ">       a[i+5] = a[i+5]*b + c;\n",
      ">       a[i+6] = a[i+6]*b + c;\n",
      ">       a[i+7] = a[i+7]*b + c;\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      ">     \n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "diff fma_loop_host.c fma_loop_host_opt.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff fma_loop_dev.cu fma_loop_dev_opt.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can exploit vectorization, instruction level parallelism, and/or loop transformations to get a boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.o *.optrpt *.so fma_prof fma_prof_opt\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_prof.o fma_prof.c\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_omp.o fma_omp.c\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_loop_host.o fma_loop_host.c\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O3 -dc -o fma_cuda.o fma_cuda.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O3 -dc -o fma_loop_dev.o fma_loop_dev.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -dlink  fma_cuda.o fma_loop_dev.o -o fma_cuda_link.o\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "icpc -qopenmp -shared -Wl,-soname,libfma_cuda.so -o libfma_cuda.so fma_cuda_link.o fma_cuda.o fma_loop_dev.o -L/usr/local/pacerepov1/cuda/8.0.44/lib64 -Wl,-rpath,/usr/local/pacerepov1/cuda/8.0.44/lib64 -lcudart\n",
      "icpc -qopenmp -o fma_prof fma_prof.o fma_omp.o fma_loop_host.o libfma_cuda.so -Wl,-rpath,.\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_loop_host_opt.o fma_loop_host_opt.c\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -O3 -dc -o fma_loop_dev_opt.o fma_loop_dev_opt.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -dlink  fma_cuda.o fma_loop_dev_opt.o -o fma_cuda_link_opt.o\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "icpc -qopenmp -shared -Wl,-soname,libfma_cuda_opt.so -o libfma_cuda_opt.so fma_cuda_link_opt.o fma_cuda.o fma_loop_dev_opt.o -L/usr/local/pacerepov1/cuda/8.0.44/lib64 -Wl,-rpath,/usr/local/pacerepov1/cuda/8.0.44/lib64 -lcudart\n",
      "icpc -qopenmp -o fma_prof_opt fma_prof.o fma_omp.o fma_loop_host_opt.o libfma_cuda_opt.so -Wl,-rpath,.\n",
      "OMP_PROC_BIND=spread OMP_NUM_THREADS=28  ./fma_prof_opt 8388608 0 -1 -1 12 0.5 3.0\n",
      "[./fma_prof_opt] Nh = 8388608, Nd = 0, T = 12, default block size\n",
      "[./fma_prof_opt]: 2.450943e-04 elapsed seconds\n",
      "[./fma_prof_opt]: 201326592 flops executed\n",
      "[./fma_prof_opt]: 8.214250e+11 flop/s\n"
     ]
    }
   ],
   "source": [
    "make clean\n",
    "make run_fma_prof_opt Nh=8388608 Nd=0 T=12 COPTFLAGS='-O3 -xHost' CUOPTFLAGS='-O3' # modify this for peak flop/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting this work\n",
    "\n",
    "**Workstation exercise 1 (1 pt):** When you have completed the rest of this assignment, `git add` the changes to this file, the source files you modified, and any scripts you added, and `git commit` them.  Having commited your changes, you should `git push` them to the private repository that you have on `github.gatech.edu`.\n",
    "\n",
    "Our TA Han Sol Suh will email each of you a individualized [deploy key](https://developer.github.com/v3/guides/managing-deploy-keys/) that will allow him to read the contents of your repository.  \n",
    "\n",
    "**Assignments need to be formally submitted to canvas,** but the totality of your submission on canvas should be a git revision hash or branch name indicating the version of your repository we should use to grade the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
