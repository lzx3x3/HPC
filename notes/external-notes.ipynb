{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Notes and Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. [\"Fooling the Masses\"](https://blogs.fau.de/hager/archives/5260) article series from Georg Hager\n",
    "\n",
    "Discusses how to understand how performance metrics are presented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hager & Wellein \"Node Level Performance Engineering\"\n",
    "\n",
    "[slides](https://moodle.rrze.uni-erlangen.de/pluginfile.php/12220/mod_resource/content/10/01_Arch.pdf)\n",
    "\n",
    "These slides are as in-depth a reference as we need in this class for most hardware related issues.\n",
    "\n",
    "**Index** (numbering is by the slide number, not by the pdf page number, which doesn't align exactly):\n",
    "\n",
    "- Parallelism within a CPU (20-61):\n",
    "    - Basic CPU architecture (21-25)\n",
    "    - Pipelining (27-39)\n",
    "    - Superscalarity (multiple functional units) (40-45)\n",
    "    - SIMD Vectorization (46-58)\n",
    "    - Combining the above for peak flop calculations (59-61)\n",
    "    \n",
    "- The memory system (68-96):\n",
    "    - Caches & basics (typical bandwidths & latencies, cache lines, prefetching) (69-76)\n",
    "    - Spatial locality (78-83)\n",
    "    - Temporal locality & cache policies (83-92)\n",
    "    - Cache coherence (93-96)\n",
    "    - Cache coherent non-uniform memory access (NUMA) (97-102) (Includes _first-touch_ policy for memory initialization)\n",
    "    - Node-topology nomenclature (showing the differences between node, socket, NUMA domain, cache group, and processors) (103)\n",
    "    \n",
    "- Benchmarking (STREAM Triad) (104-113)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. McCalpin \"Memory Bandwidth and System Balance in HPC Systems\"\n",
    "\n",
    "[slides](http://sites.utexas.edu/jdm4372/2016/11/22/sc16-invited-talk-memory-bandwidth-and-system-balance-in-hpc-systems/)\n",
    "\n",
    "Good historical data on how _machine balances_ have been changing over the years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prof. Vuduc's old CSE 6230 slides\n",
    "\n",
    "### A. [OpenMP](cse6230-fa14--04-omp.pdf)\n",
    "\n",
    "### B. [CUDA](http://vuduc.org/cse6230/slides/cse6230-fa14--05-cuda.pdf)\n",
    "\n",
    "**Index:**\n",
    "\n",
    "- Review of CPU parallelism and threading model (2-13)\n",
    "- GPU / CPU architecture comparison (13-16)\n",
    "- GPU execution (offloading) model (kernel launches, thread blocks, warps, threads) (17(slide number)-38(pdf page number))\n",
    "- Thread indexing hierachy and GPU memory type hierarchy (local, shared, global, texture) (39-42)\n",
    "- Synchronization (47)\n",
    "- Scheduling (48)\n",
    "- Execution (49)\n",
    "- Performance notes (Thread divergence, occupancy, bandwidth utilization) (50-55)\n",
    "\n",
    "### C. [GPU Tuning](http://vuduc.org/cse6230/slides/cse6230-fa14--07-gpu-tuning-1.pdf)\n",
    "\n",
    "**Index:**\n",
    "\n",
    "- Review of execution model (1-9)\n",
    "- Arithmetic intensity and machine balance (12-19)\n",
    "- The roofline model (20-26)\n",
    "- Thread-level parallelism vs. instruction level parallelism (27-42)\n",
    "- Register usage (43-46)\n",
    "- Example: tuning reductions (43-92)\n",
    "\n",
    "### D. [Case study: tuning Fast Multipole for bloodflow](http://vuduc.org/cse6230/slides/HPCA-tutorial-part-2.pdf) Slides 18-68\n",
    "\n",
    "### E. [MPI](http://vuduc.org/cse6230/slides/cse6230-fa14--06-mpi.pdf)\n",
    "\n",
    "### F. [Distributed Dense Linear Algebra](http://vuduc.org/cse6230/slides/cse6230-fa14--lab6-notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [OpenMP for GPUs](https://exascaleproject.org/wp-content/uploads/2017/05/OpenMP-4.5-and-Beyond-SOLLVE-part-21.pdf), Tom Scogland & Oscar Hernandez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prof. Chow's old CSE 6230 slides\n",
    "\n",
    "### A. [False sharing](https://www.cc.gatech.edu/%7Eechow/ipcc/hpc-course/11_mini2.pdf)\n",
    "\n",
    "A pitfall of the cache-coherent NUMA memory model\n",
    "\n",
    "### B. [Molecular simulation principles](https://www.cc.gatech.edu/%7Eechow/ipcc/hpc-course/05_celllist.pdf)\n",
    "\n",
    "### C. [Sparse Matrix Data Structures](https://www.cc.gatech.edu/%7Eechow/ipcc/hpc-course/16_sparsemat.pdf)\n",
    "\n",
    "### D. [Graph Partitioning](https://www.cc.gatech.edu/%7Eechow/ipcc/hpc-course/17_graphpart.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [OpenMP Tutorial](https://computing.llnl.gov/tutorials/openMP/) from Lawrence Livermore National Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [OpenMP Examples](https://www.openmp.org/wp-content/uploads/openmp-examples-4.5.0.pdf) from the OpenMP committee\n",
    "\n",
    "Good small examples that illustrate the finer points of synchronization, scheduling, memory privacy, memory movement for GPU programming, thread affinity, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. [OpenMP Performance Issues](https://www.archer.ac.uk/training/course-material/2015/12/ShMem_OpenMP_York/Slides/L09-performance.pdf) From Archer, the UK National Supercomputing Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. [Valgrind](http://valgrind.org/docs/manual/quick-start.html) how-to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. [MPI RMA](https://press3.mcs.anl.gov/atpesc/files/2016/08/Thakur_1ooaug2_OneSided.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. [ParResKernels](https://github.com/ParRes/Kernels/): Multiple implementations of different \"kernels\" (distillations of real applications) in multiple parallel programming paradigms, including OpenMP, OpenMP with device support, MPI Two-sided (MPI1), and MPI One-sided (MPI2, MPI3) by Jeff Hammond and others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.[Parallel Sorting](https://drive.google.com/file/d/1_sUsTY8NNUyUjGySdek9C2UGuaVxXQGe/view) by Aydin Buluc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
