{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running MPI jobs on PACE-ICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. If you are only running on one node,\n",
    "\n",
    "you may use the `coc-ice` queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsub -d $PWD -q coc-ice -n -l nodes=1:ppn=28,walltime=01:00:00 -I -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. If you are running on more than one node\n",
    "(we can use up to 128 processes), you must use the `coc-ice-multi` queue.  Walltimes are limited to 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsub -d $PWD -q coc-ice-multi -n -l nodes=4:ppn=28,walltime=00:30:00 -I -X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. If you use the `cse6230/core` modules,\n",
    "you will use the Intel `impi` implementation of MPI.  The `mpirun` launcher is more reliable than the `mpiexec` launcher for `impi` on pace-ice.\n",
    "\n",
    "**You should specify which resources are available to you, which are listed in `${PBS_NODEFILE}`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpirun -f ${PBS_NODEFILE} -np ${PBS_NP} ./osu_latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pin processes to core (much like thread affinity in OpenMP), you should use the environment variables.  Environment variables can be added to the launcher like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpirun -f ${PBS_NODEFILE} -np ${PBS_NP} -env I_MPI_PIN 1 ./osu_latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. If you use the cse6230/gcc-omp-gpu modules,\n",
    "you will use the `mvapich2` implementation of MPI.  Both `mpiexec` and `mpirun` work.  You can pin processes with `MV2_ENABLE_AFFINITY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module unload cse6230\n",
    "module load cse6230/gcc-omp-gpu\n",
    "\n",
    "mpirun -f ${PBS_NODEFILE} -np 2 -env MV2_ENABLE_AFFINITY 1 ./osu_latency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
