{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Processors Alone\n",
    "\n",
    "![](images/cpu.jpg)\n",
    "\n",
    "$$\\Huge\\color{blue}{\\text{Registers}}$$\n",
    "\n",
    "$$\\Huge\\color{red}{\\text{Scheduler}}$$\n",
    "\n",
    "$$\\Huge\\color{green}{\\text{Functional Units}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### When introducing OpenMP (which we will look at in more depth later in the class), it's typical to start with a simple example of how easy it makes it to parallelize your code:\n",
    "\n",
    "```C\n",
    "/* We added one pragma and it's parallel! */\n",
    "#pragma omp parallel for\n",
    "for (i = 0; i < N; i++) {\n",
    "  A[i] = func (b[i], c[i]);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In fact, parallelizing you code can be even simpler, you don't even have to change it.\n",
    "\n",
    "You simply have to change from this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $CSE6230_DIR/assignments/2-flops\n",
    "cc -g -c -std=c99 -o fma_loop_host.o fma_loop_host.c -O0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc -g -c -std=c99 -o fma_loop_host_opt.o fma_loop_host.c -O3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By asking the compiler to try its best to optimize my code, it is able to exploit parallelism within the CPU core, even for my serial program.\n",
    "\n",
    "---\n",
    "\n",
    "Questions we'd like to answer today:\n",
    "\n",
    "- What kind of parallelism is available in a single core, and how much of it?\n",
    "- How can I exploit it?\n",
    "- Can all applications exploit it?\n",
    "- How can I make the compiler do the work for me?\n",
    "- How does the parallelism on a CPU core compare to the parallelism in a GPU?\n",
    "\n",
    "\n",
    "Tools we will use today:\n",
    "\n",
    "- Code compilers, like `cc` above, focusing on their optimization options.  `cc` is typically an alias for a major compiler (you can typically run `man CC` or `CC --help` to get big lists of optimization and other options)\n",
    "  * GNU `gcc`\n",
    "  * LLVM `clang`\n",
    "  * NVIDIA `nvcc`\n",
    "  * Vendor specific (like Intel `icc`)\n",
    "  (focus on their optimization options)\n",
    "- Code decompilers and diagnostics (to see what the heck compilers are doing)\n",
    "- Hardware counters for things that happen in the processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For many, many applications, optimal performance can't be achieved by optimizing just the processor's performance alone: we have to optimize it's interactions with the memory system. That is why I'd like to finish the \"Processors alone\" module today.\n",
    "\n",
    "Luckily, optimizing the processor in isolation is something that compilers are quite good at.\n",
    "\n",
    "If you have to take away one keep concept today, it is **Little's law**, which will often tell you how to structure your code to set the compiler up for success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recall the end stage of compilation we discussed in the first lecture: machine code\n",
    "\n",
    "When I compiled `fma_loop_host.o` above, it created a file with those instructions.  It's encoded in binary, so opening it up in a text editor won't tell us much, but I can still find out what those machine code instructions are by decompiling the binary into assembly language.  The utility that let's me do that is called `objdump`.\n",
    "\n",
    "(We haven't talked about how CUDA code is different, but for now let's just mention that it comes with its own decompiler: `cuobjdump`)\n",
    "\n",
    "Here is the entirety of `fma_loop_host.c` from assignment 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m#\u001b[39;49;00m\u001b[36minclude\u001b[39;49;00m \u001b[37m\"fma_host.h\"\u001b[39;49;00m\u001b[36m\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m/* fma_loop: Fused Multiply Add loop\u001b[39;49;00m\n",
      "\u001b[37m *           -     -        -\u001b[39;49;00m\n",
      "\u001b[37m *\u001b[39;49;00m\n",
      "\u001b[37m * a[:] = a[:] * b + c, T times\u001b[39;49;00m\n",
      "\u001b[37m *\u001b[39;49;00m\n",
      "\u001b[37m * Inputs:\u001b[39;49;00m\n",
      "\u001b[37m * N : the size of the array\u001b[39;49;00m\n",
      "\u001b[37m * T : the number of loops\u001b[39;49;00m\n",
      "\u001b[37m * b : the multiplier\u001b[39;49;00m\n",
      "\u001b[37m * c : the shift\u001b[39;49;00m\n",
      "\u001b[37m *\u001b[39;49;00m\n",
      "\u001b[37m * Input-Outputs:\u001b[39;49;00m\n",
      "\u001b[37m * a : the array\u001b[39;49;00m\n",
      "\u001b[37m */\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "\u001b[32mfma_loop_host\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "    \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m j = \u001b[34m0\u001b[39;49;00m; j < T; j++) {\n",
      "      a[i] = a[i] * b + c;\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat fma_loop_host.c | pygmentize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fma_loop_host.o:     file format \u001b[33melf64-x86-64\u001b[39;49;00m\n",
      "\n",
      "\n",
      "Disassembly of section .text:\n",
      "\n",
      "\u001b[34m0000000000000000\u001b[39;49;00m <\u001b[32mfma_loop_host\u001b[39;49;00m>:\n",
      " * Input-Outputs:\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_host (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "   0:\t\u001b[34m55 \u001b[39;49;00m                  \t\u001b[32mpush\u001b[39;49;00m   \u001b[31m%rbp\u001b[39;49;00m\n",
      "   1:\t\u001b[34m48 89 e5 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%rsp\u001b[39;49;00m,\u001b[31m%rbp\u001b[39;49;00m\n",
      "   4:\t\u001b[34m89 7d ec \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%edi\u001b[39;49;00m,-\u001b[34m0x14\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "   7:\t\u001b[34m89 75 e8 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%esi\u001b[39;49;00m,-\u001b[34m0x18\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "   a:\t\u001b[34m48 89 55 e0 \u001b[39;49;00m         \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%rdx\u001b[39;49;00m,-\u001b[34m0x20\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "   e:\t\u001b[34mf3 0f 11 45 dc \u001b[39;49;00m      \t\u001b[32mmovss\u001b[39;49;00m  \u001b[31m%xmm0\u001b[39;49;00m,-\u001b[34m0x24\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "  13:\t\u001b[34mf3 0f 11 4d d8 \u001b[39;49;00m      \t\u001b[32mmovss\u001b[39;49;00m  \u001b[31m%xmm1\u001b[39;49;00m,-\u001b[34m0x28\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  18:\t\u001b[34mc7 45 f8 00 00 00 00 \u001b[39;49;00m\t\u001b[32mmovl\u001b[39;49;00m   \u001b[31m$0x0\u001b[39;49;00m,-\u001b[34m0x8\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "  1f:\t\u001b[34meb 46 \u001b[39;49;00m               \t\u001b[32mjmp\u001b[39;49;00m    \u001b[34m67\u001b[39;49;00m <\u001b[31mfma_loop_host\u001b[39;49;00m+\u001b[34m0x67\u001b[39;49;00m>\n",
      "    \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m j = \u001b[34m0\u001b[39;49;00m; j < T; j++) {\n",
      "  21:\t\u001b[34mc7 45 fc 00 00 00 00 \u001b[39;49;00m\t\u001b[32mmovl\u001b[39;49;00m   \u001b[31m$0x0\u001b[39;49;00m,-\u001b[34m0x4\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "  28:\t\u001b[34meb 31 \u001b[39;49;00m               \t\u001b[32mjmp\u001b[39;49;00m    \u001b[34m5b\u001b[39;49;00m <\u001b[31mfma_loop_host\u001b[39;49;00m+\u001b[34m0x5b\u001b[39;49;00m>\n",
      "      a[i] = a[i] * b + c;\n",
      "  2a:\t\u001b[34m8b 45 f8 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    -\u001b[34m0x8\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%eax\u001b[39;49;00m\n",
      "  2d:\t\u001b[34m48 98 \u001b[39;49;00m               \t\u001b[32mcltq\u001b[39;49;00m   \n",
      "  2f:\t\u001b[34m48 c1 e0 02 \u001b[39;49;00m         \t\u001b[32mshl\u001b[39;49;00m    \u001b[31m$0x2\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  33:\t\u001b[34m48 03 45 e0 \u001b[39;49;00m         \t\u001b[32madd\u001b[39;49;00m    -\u001b[34m0x20\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%rax\u001b[39;49;00m\n",
      "  37:\t\u001b[34m8b 55 f8 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    -\u001b[34m0x8\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%edx\u001b[39;49;00m\n",
      "  3a:\t\u001b[34m48 63 d2 \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m\n",
      "  3d:\t\u001b[34m48 c1 e2 02 \u001b[39;49;00m         \t\u001b[32mshl\u001b[39;49;00m    \u001b[31m$0x2\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m\n",
      "  41:\t\u001b[34m48 03 55 e0 \u001b[39;49;00m         \t\u001b[32madd\u001b[39;49;00m    -\u001b[34m0x20\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%rdx\u001b[39;49;00m\n",
      "  45:\t\u001b[34mf3 0f 10 02 \u001b[39;49;00m         \t\u001b[32mmovss\u001b[39;49;00m  (\u001b[31m%rdx\u001b[39;49;00m),\u001b[31m%xmm0\u001b[39;49;00m\n",
      "  49:\t\u001b[34mf3 0f 59 45 dc \u001b[39;49;00m      \t\u001b[32mmulss\u001b[39;49;00m  -\u001b[34m0x24\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%xmm0\u001b[39;49;00m\n",
      "  4e:\t\u001b[34mf3 0f 58 45 d8 \u001b[39;49;00m      \t\u001b[32maddss\u001b[39;49;00m  -\u001b[34m0x28\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%xmm0\u001b[39;49;00m\n",
      "  53:\t\u001b[34mf3 0f 11 00 \u001b[39;49;00m         \t\u001b[32mmovss\u001b[39;49;00m  \u001b[31m%xmm0\u001b[39;49;00m,(\u001b[31m%rax\u001b[39;49;00m)\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_host (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "    \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m j = \u001b[34m0\u001b[39;49;00m; j < T; j++) {\n",
      "  57:\t\u001b[34m83 45 fc 01 \u001b[39;49;00m         \t\u001b[32maddl\u001b[39;49;00m   \u001b[31m$0x1\u001b[39;49;00m,-\u001b[34m0x4\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "  5b:\t\u001b[34m8b 45 fc \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    -\u001b[34m0x4\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%eax\u001b[39;49;00m\n",
      "  5e:\t\u001b[34m3b 45 e8 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    -\u001b[34m0x18\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%eax\u001b[39;49;00m\n",
      "  61:\t\u001b[34m7c c7 \u001b[39;49;00m               \t\u001b[32mjl\u001b[39;49;00m     \u001b[34m2a\u001b[39;49;00m <\u001b[31mfma_loop_host\u001b[39;49;00m+\u001b[34m0x2a\u001b[39;49;00m>\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_host (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  63:\t\u001b[34m83 45 f8 01 \u001b[39;49;00m         \t\u001b[32maddl\u001b[39;49;00m   \u001b[31m$0x1\u001b[39;49;00m,-\u001b[34m0x8\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m)\n",
      "  67:\t\u001b[34m8b 45 f8 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    -\u001b[34m0x8\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%eax\u001b[39;49;00m\n",
      "  6a:\t\u001b[34m3b 45 ec \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    -\u001b[34m0x14\u001b[39;49;00m(\u001b[31m%rbp\u001b[39;49;00m),\u001b[31m%eax\u001b[39;49;00m\n",
      "  6d:\t\u001b[34m7c b2 \u001b[39;49;00m               \t\u001b[32mjl\u001b[39;49;00m     \u001b[34m21\u001b[39;49;00m <\u001b[31mfma_loop_host\u001b[39;49;00m+\u001b[34m0x21\u001b[39;49;00m>\n",
      "    \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m j = \u001b[34m0\u001b[39;49;00m; j < T; j++) {\n",
      "      a[i] = a[i] * b + c;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "  6f:\t\u001b[34mc9 \u001b[39;49;00m                  \t\u001b[32mleaveq\u001b[39;49;00m \n",
      "  70:\t\u001b[34mc3 \u001b[39;49;00m                  \t\u001b[32mretq\u001b[39;49;00m   \n"
     ]
    }
   ],
   "source": [
    "objdump -Sd fma_loop_host.o | pygmentize -l c-objdump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that, as illegible as this is, it would be much worse if we didn't have source code interspersed with instructions.  You should always compile C code with `-g` and CUDA with ~~`-G`~~ `-lineinfo` [`-G` always turns off optimizations]  for this reason and others.)\n",
    "\n",
    "For our purposes, this assembly code has three types of instructions:\n",
    "\n",
    "- Instructions that take **registers** as inputs (those things that are addressed like `%rax` and `%rbp`) and\n",
    "  write their outputs over the locations of their inputs.  Examples are floating point operations like `mulss` (multiply two single precision numbers together), integer operations like `addl` (add two 32-bit integers), and logical operations like `cmp` (determine if one integer is less than another and write the output to a special register).\n",
    "\n",
    "  * In hardware, registers are data locations in a register file: the storage closest to the execution units.\n",
    "    Register space is quite dear, so to reflect that, most instruction sets have a limited number of registers (see\n",
    "    e.g. the wikipedia page for the [AVX512](https://en.wikipedia.org/wiki/AVX-512#Extended_registers) instruction \n",
    "    set.).  When a thread has too many computations to keep track of, data that would otherwise be stored in a register is *spilled* to memory, which slows things down.  I mention all of this just to say that one things compilers are trying to do is figure out how to squeeze your complex instructions into the limited scratchpad space provided by the registers.\n",
    "    \n",
    "- Instructions that load and store data from memory like `mov`: we're not going to talk about open can of worms today.\n",
    "\n",
    "- Branching instructions that control the flow of instructions like `jl` (jump to a given code location based on the outcome of a comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for our simple purposes today, a **thread** is:\n",
    "\n",
    "- a stream of instructions, with\n",
    "- a limited set of registers as a workspace for partial computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a thread is executed\n",
    "\n",
    "(This is a simplification of the [classic RISC pipeline](https://en.wikipedia.org/wiki/Classic_RISC_pipeline))\n",
    "\n",
    "1. An instruction like `add    %rdx,%rax` is:\n",
    "\n",
    "  1. *fetched* from the instruction queue, \n",
    "  2. *decoded* (it's operation and register inputs / outputs are identified), \n",
    "  3. **executed** (the part we care about), and\n",
    "  4. *written back* to registers\n",
    "  \n",
    "2. Move to the next instruction and repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining\n",
    "\n",
    "If a *cycle* is the smallest unit of time of a processor, and an instruction has multiple steps (each step takes a cycle), does that means that an instruction takes multiple cycles?\n",
    "\n",
    "Yes!  Let's say $k$ cycles.\n",
    "\n",
    "Does that mean that a processor takes $kN$ cycles to complete $N$ instructions?\n",
    "\n",
    "No! Instructions are **Pipelined:**\n",
    "\n",
    "![pseudorisc pipeline](./images/pipeline-1.jpg)\n",
    "\n",
    "The key thing to understand about pipelined operations:\n",
    "\n",
    "**The results of an operation can't be inputs to another operation until they exit\n",
    "the pipeline.**\n",
    "\n",
    "Any cycle of a pipeline when there isn't a new input is a *bubble*.\n",
    "\n",
    "The *efficiency* (work / cycle) of your pipelined algorithm is the *fraction of non-bubble cycles*.\n",
    "\n",
    "**A fully efficient pipelined algorithm has at least $k$ concurrent independent operations at any point in time, where $k$ is the depth of the pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I think that the way that many diagrams show pipelined instructions (time axis horizontal, data axis vertical, instructions labeled) is not helpful, because the \"pipe\" in the pipeline is always moving, and because the diagram gets larger in both dimensions as time goes on.  I prefer to have *instructions* on the vertical axis and *data* labeled on the diagram, because that way the diagram only grows on one axis, and each column looks like a time slice of the pipeline)\n",
    "\n",
    "![pipeline](./images/pipeline-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines and branching\n",
    "\n",
    "Even in our simple program, we saw that my nice clean breakdown of register-register instructions and memory instructions wasn't respected: some instructions like `mulss  -0x24(%rbp),%xmm0` combine a memory access\n",
    "(`-0x24(%rbp)` accesses a memory location stored in `%rbp`, offset by a certain amount).\n",
    "\n",
    "More complex instructions require more decoding: the pipeline of operations before **execute** is quite long on a modern CPU.\n",
    "\n",
    "![long pipeline](./images/pipeline-3.jpg)\n",
    "\n",
    "That is why branching instructions are hard to combine with pipelined execution.  We don't know which instruction\n",
    "should go into the pipeline, it depends on the output of a computation like a comparison.  The CPU could:\n",
    "\n",
    "- Hold up everything to wait until it is known which branch to take (always stall the pipeline, bad)\n",
    "- Try to *predict* which branch will be taken an keep feeding the pipeline with that branch (bad when there is a *misprediction*)\n",
    "\n",
    "Branch prediction is a complicated, sophisticated thing on modern CPUs.  In your programming, you should assume the following:\n",
    "\n",
    "- Computers are good are recognizing patterns: there is a branch in every loop of a for-loop, but if you keep looping back, it will eventually start predicting that is the branch to take, and a branch will be a neglible part of the execution time.  For loops with known bounds can also be **unrolled** meaning copy-pasted the right number of times with no branching at all.\n",
    "\n",
    "```C\n",
    "for (int i = 0; i < N; i++) { /* if N = 10000000000, branch prediction will almost always be right */\n",
    "    /* ... */\n",
    "}\n",
    "```\n",
    "\n",
    "```C\n",
    "for (int  i = 0; i < 8; i++) {\n",
    "  /* If the bound is known at compile time, the loop can be unrolled with no branching */\n",
    "  /* ... */\n",
    "}\n",
    "```\n",
    "\n",
    "```C\n",
    "/* You can give the compiler hints about how you want to break up a loop in to unrolled sections,\n",
    "   reducing the number of branches */\n",
    "#pragma unroll(8)\n",
    "for (int i = 0; i < N; i++) {\n",
    "    /* ... */\n",
    "}\n",
    "```\n",
    "\n",
    "- If your branching has no patterns, then you should expect lots of branch misprediction: the instruction pipeline \n",
    "  has to be cleared out, leading to a stall in your code *proportional in length to the pipeline depth* (~10-20 cycles)\n",
    "  \n",
    "- Branch misprediction is the kind of hardware event that can be counted by a performance counter like `perf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -qopt-report=5 -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_prof.o fma_prof.c\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc -g -Wall -std=c99 -fPIC -O3 -xHost -qopt-report=5 -I/usr/local/pacerepov1/cuda/8.0.44/include -qopenmp -c -o fma_omp.o fma_omp.c\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC'  -dc -o fma_cuda.o fma_cuda.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC'  -dc -o fma_loop_dev.o fma_loop_dev.cu\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc -ccbin=icpc -Xcompiler '-fPIC' -dlink  fma_cuda.o fma_loop_dev.o -o fma_cuda_link.o\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "icpc -qopenmp -shared -Wl,-soname,libfma_cuda.so -o libfma_cuda.so fma_cuda_link.o fma_cuda.o fma_loop_dev.o -L/usr/local/pacerepov1/cuda/8.0.44/lib64 -Wl,-rpath,/usr/local/pacerepov1/cuda/8.0.44/lib64 -lcudart\n",
      "icpc -qopenmp -o fma_prof fma_prof.o fma_omp.o fma_loop_host.o libfma_cuda.so -Wl,-rpath,.\n",
      "OMP_PROC_BIND=spread OMP_NUM_THREADS=1 perf stat -v ./fma_prof 256 256 -1 -1 1048576 0.5 3.0\n",
      "Warning:\n",
      "stalled-cycles-frontend event is not supported by the kernel.\n",
      "Warning:\n",
      "stalled-cycles-backend event is not supported by the kernel.\n",
      "[./fma_prof] Nh = 256, Nd = 256, T = 1048576, default block size\n",
      "[./fma_prof]: 1.034894e+00 elapsed seconds\n",
      "[./fma_prof]: 536870912 flops executed\n",
      "[./fma_prof]: 5.187689e+08 flop/s\n",
      "task-clock: 1037314164 1037314164 1037314164\n",
      "context-switches: 24 1037314164 1037314164\n",
      "cpu-migrations: 1 1037314164 1037314164\n",
      "page-faults: 977 1037314164 1037314164\n",
      "cycles: 3239895627 1037337825 1037337825\n",
      "stalled-cycles-frontend: 0 0 0\n",
      "stalled-cycles-backend: 0 0 0\n",
      "instructions: 4314620525 1037337825 1037337825\n",
      "branches: 271911850 1037337825 1037337825\n",
      "branch-misses: 42928 1037337825 1037337825\n",
      "\n",
      " Performance counter stats for './fma_prof 256 256 -1 -1 1048576 0.5 3.0':\n",
      "\n",
      "       1037.314164      task-clock (msec)         #    0.991 CPUs utilized          \n",
      "                24      context-switches          #    0.023 K/sec                  \n",
      "                 1      cpu-migrations            #    0.001 K/sec                  \n",
      "               977      page-faults               #    0.942 K/sec                  \n",
      "     3,239,895,627      cycles                    #    3.123 GHz                    \n",
      "   <not supported>      stalled-cycles-frontend  \n",
      "   <not supported>      stalled-cycles-backend   \n",
      "     4,314,620,525      instructions              #    1.33  insns per cycle        \n",
      "       271,911,850      branches                  #  262.131 M/sec                  \n",
      "            42,928      branch-misses             #    0.02% of all branches        \n",
      "\n",
      "       1.047001689 seconds time elapsed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd $CSE6230_DIR/assignments/2-flops\n",
    "make run_fma_prof PERF=\"perf stat -v\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing instructions\n",
    "\n",
    "Like I said, the depth of the pipeline before and after execution really only affects us when there is branching.  Let's talk about *execute*:\n",
    "\n",
    "- Different types of instructions are executed on different *functional units*:\n",
    "\n",
    "  - *ALU*: arithmetic and logic unit\n",
    "  - *FPU*: floating point unit\n",
    "  - etc.\n",
    "  \n",
    "See, e.g., the [Kaby Lake](https://en.wikichip.org/wiki/intel/microarchitectures/kaby_lake) diagram from Wikichip that we saw in the first lecture.  This is what the cartoon at the top of the lecture is supposed to be a simplification of.\n",
    "\n",
    "![Kaby Lake](./images/kabylake.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superscalarity\n",
    "\n",
    "There are multiple functional units in a processor.  In the pipeline diagrams we've seen so far, there is only one `execute` instruction happening per cycle.  That would mean that only one functional units is called on per cycle, leaving the others idle.  Is that a waste of resources?\n",
    "\n",
    "It is, the diagrams are wrong! Modern CPUS are **superscalar:** there are multiple instruction pipelines that can happen at once.\n",
    "\n",
    "![superscalar pipeline](./images/pipeline-super.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we exploit superscalarity?\n",
    "\n",
    "- Some combination of a smart **scheduler,** which is able to\n",
    "  1. Look ahead several instructions,\n",
    "  2. Identify *independent* operations, and\n",
    "  3. Reorder for concurrent independence\n",
    "  \n",
    "- And a smart **compiler**, which\n",
    "  1. Knows the functional units that are available\n",
    "  2. Knows the amount of register space available and the superscalar factor, and\n",
    "  3. Tries to reorder and change which registers are used to solve the\n",
    "     optimal scheduling problem\n",
    "     \n",
    "In almost all cases, the compiler is better than you are at this: don't try to out think it.\n",
    "\n",
    "If you think the compiler is getting it wrong:\n",
    "\n",
    "- Use the decompiler to see what it's doing\n",
    "- Use *optimization reports* (like Intel `-qopt-report=5`) to ask the compiler to tell you what it's doing\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also exploit superscalarity with multiple threads\n",
    "\n",
    "When one thread has a pipeline stall, another can be issuing instructions.\n",
    "\n",
    "- If there is hardware support for multiple threads, that means they can both have their registers in the register file at the same time, and the scheduler can switch between them.  If there is OS support for multiple threads, that means the OS switches which threads have their registers in the processor at a given time.  We can talk more about this another day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how well the compiler optimizes a simple loop\n",
    "\n",
    "- **Note:** Most compilers have an options to compile with the specialized instruction set of the chip on which it is being compiled.  On pace-ice, pass `-xHost` for compiling to your current chip with `icc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m#\u001b[39;49;00m\u001b[36minclude\u001b[39;49;00m \u001b[37m\"fma_host.h\"\u001b[39;49;00m\u001b[36m\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m/* fma_loop: Fused Multiply Add loop\u001b[39;49;00m\n",
      "\u001b[37m *           -     -        -\u001b[39;49;00m\n",
      "\u001b[37m *\u001b[39;49;00m\n",
      "\u001b[37m * a[:] = a[:] * b + c, T times\u001b[39;49;00m\n",
      "\u001b[37m *\u001b[39;49;00m\n",
      "\u001b[37m * Inputs:\u001b[39;49;00m\n",
      "\u001b[37m * N : the size of the array\u001b[39;49;00m\n",
      "\u001b[37m * T : the number of loops\u001b[39;49;00m\n",
      "\u001b[37m * b : the multiplier\u001b[39;49;00m\n",
      "\u001b[37m * c : the shift\u001b[39;49;00m\n",
      "\u001b[37m *\u001b[39;49;00m\n",
      "\u001b[37m * Input-Outputs:\u001b[39;49;00m\n",
      "\u001b[37m * a : the array\u001b[39;49;00m\n",
      "\u001b[37m */\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "\u001b[32mfma_loop_short\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "    a[i] = a[i] * b + c;\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cd $CSE6230_DIR/assignments/2-flops\n",
    "cat fma_loop_short.c | pygmentize\n",
    "module unload gcc\n",
    "module load intel/16.0\n",
    "icc -g -c -std=c99 -xHost -o fma_loop_short.o fma_loop_short.c -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fma_loop_short.o:     file format \u001b[33melf64-x86-64\u001b[39;49;00m\n",
      "\n",
      "\n",
      "Disassembly of section .text:\n",
      "\n",
      "\u001b[34m0000000000000000\u001b[39;49;00m <\u001b[32mfma_loop_short\u001b[39;49;00m>:\n",
      " * Input-Outputs:\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "   0:\t\u001b[34m48 89 d1 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%rdx\u001b[39;49;00m,\u001b[31m%rcx\u001b[39;49;00m\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "   3:\t\u001b[34m85 ff \u001b[39;49;00m               \t\u001b[32mtest\u001b[39;49;00m   \u001b[31m%edi\u001b[39;49;00m,\u001b[31m%edi\u001b[39;49;00m\n",
      "   5:\t\u001b[34m0f 8e 05 01 00 00 \u001b[39;49;00m   \t\u001b[32mjle\u001b[39;49;00m    \u001b[34m110\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x110\u001b[39;49;00m>\n",
      "   b:\t\u001b[34m83 ff 10 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m$0x10\u001b[39;49;00m,\u001b[31m%edi\u001b[39;49;00m\n",
      "   e:\t\u001b[34m0f 8c 04 01 00 00 \u001b[39;49;00m   \t\u001b[32mjl\u001b[39;49;00m     \u001b[34m118\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x118\u001b[39;49;00m>\n",
      "  14:\t\u001b[34m48 89 c8 \u001b[39;49;00m            \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  17:\t\u001b[34m48 83 e0 1f \u001b[39;49;00m         \t\u001b[32mand\u001b[39;49;00m    \u001b[31m$0x1f\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  1b:\t\u001b[34m89 c0 \u001b[39;49;00m               \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%eax\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      "  1d:\t\u001b[34m85 c0 \u001b[39;49;00m               \t\u001b[32mtest\u001b[39;49;00m   \u001b[31m%eax\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      "  1f:\t\u001b[34m74 10 \u001b[39;49;00m               \t\u001b[32mje\u001b[39;49;00m     \u001b[34m31\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x31\u001b[39;49;00m>\n",
      "  21:\t\u001b[34ma8 03 \u001b[39;49;00m               \t\u001b[32mtest\u001b[39;49;00m   \u001b[31m$0x3\u001b[39;49;00m,\u001b[31m%al\u001b[39;49;00m\n",
      "  23:\t\u001b[34m0f 85 ef 00 00 00 \u001b[39;49;00m   \t\u001b[32mjne\u001b[39;49;00m    \u001b[34m118\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x118\u001b[39;49;00m>\n",
      "  29:\t\u001b[34mf7 d8 \u001b[39;49;00m               \t\u001b[32mneg\u001b[39;49;00m    \u001b[31m%eax\u001b[39;49;00m\n",
      "  2b:\t\u001b[34m83 c0 20 \u001b[39;49;00m            \t\u001b[32madd\u001b[39;49;00m    \u001b[31m$0x20\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      "  2e:\t\u001b[34mc1 e8 02 \u001b[39;49;00m            \t\u001b[32mshr\u001b[39;49;00m    \u001b[31m$0x2\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      "  31:\t\u001b[34m8d 50 10 \u001b[39;49;00m            \t\u001b[32mlea\u001b[39;49;00m    \u001b[34m0x10\u001b[39;49;00m(\u001b[31m%rax\u001b[39;49;00m),\u001b[31m%edx\u001b[39;49;00m\n",
      "  34:\t\u001b[34m3b fa \u001b[39;49;00m               \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%edi\u001b[39;49;00m\n",
      "  36:\t\u001b[34m0f 8c dc 00 00 00 \u001b[39;49;00m   \t\u001b[32mjl\u001b[39;49;00m     \u001b[34m118\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x118\u001b[39;49;00m>\n",
      "  3c:\t\u001b[34m89 fa \u001b[39;49;00m               \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%edi\u001b[39;49;00m,\u001b[31m%edx\u001b[39;49;00m\n",
      "  3e:\t\u001b[34m33 f6 \u001b[39;49;00m               \t\u001b[32mxor\u001b[39;49;00m    \u001b[31m%esi\u001b[39;49;00m,\u001b[31m%esi\u001b[39;49;00m\n",
      "  40:\t\u001b[34m2b d0 \u001b[39;49;00m               \t\u001b[32msub\u001b[39;49;00m    \u001b[31m%eax\u001b[39;49;00m,\u001b[31m%edx\u001b[39;49;00m\n",
      "  42:\t\u001b[34m83 e2 0f \u001b[39;49;00m            \t\u001b[32mand\u001b[39;49;00m    \u001b[31m$0xf\u001b[39;49;00m,\u001b[31m%edx\u001b[39;49;00m\n",
      "  45:\t\u001b[34mf7 da \u001b[39;49;00m               \t\u001b[32mneg\u001b[39;49;00m    \u001b[31m%edx\u001b[39;49;00m\n",
      "  47:\t\u001b[34m03 d7 \u001b[39;49;00m               \t\u001b[32madd\u001b[39;49;00m    \u001b[31m%edi\u001b[39;49;00m,\u001b[31m%edx\u001b[39;49;00m\n",
      "  49:\t\u001b[34m48 85 c0 \u001b[39;49;00m            \t\u001b[32mtest\u001b[39;49;00m   \u001b[31m%rax\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  4c:\t\u001b[34m76 17 \u001b[39;49;00m               \t\u001b[32mjbe\u001b[39;49;00m    \u001b[34m65\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x65\u001b[39;49;00m>\n",
      "    a[i] = a[i] * b + c;\n",
      "  4e:\t\u001b[34mc5 fa 10 14 b1 \u001b[39;49;00m      \t\u001b[32mvmovss\u001b[39;49;00m (\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rsi\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m),\u001b[31m%xmm2\u001b[39;49;00m\n",
      "  53:\t\u001b[34mc4 e2 79 a9 d1 \u001b[39;49;00m      \t\u001b[32mvfmadd213ss\u001b[39;49;00m \u001b[31m%xmm1\u001b[39;49;00m,\u001b[31m%xmm0\u001b[39;49;00m,\u001b[31m%xmm2\u001b[39;49;00m\n",
      "  58:\t\u001b[34mc5 fa 11 14 b1 \u001b[39;49;00m      \t\u001b[32mvmovss\u001b[39;49;00m \u001b[31m%xmm2\u001b[39;49;00m,(\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rsi\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m)\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  5d:\t\u001b[34m48 ff c6 \u001b[39;49;00m            \t\u001b[32minc\u001b[39;49;00m    \u001b[31m%rsi\u001b[39;49;00m\n",
      "  60:\t\u001b[34m48 3b f0 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%rax\u001b[39;49;00m,\u001b[31m%rsi\u001b[39;49;00m\n",
      "  63:\t\u001b[34m72 e9 \u001b[39;49;00m               \t\u001b[32mjb\u001b[39;49;00m     \u001b[34m4e\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x4e\u001b[39;49;00m>\n",
      " *\n",
      " * Input-Outputs:\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "  65:\t\u001b[34mc4 e2 7d 18 \u001b[39;49;00m         \u001b[33m\t(bad)  \u001b[39;49;00m\n",
      "  69:\t\u001b[34md9 c4 \u001b[39;49;00m               \t\u001b[32mfld\u001b[39;49;00m    \u001b[31m%st\u001b[39;49;00m(\u001b[34m4\u001b[39;49;00m)\n",
      "  6b:\t\u001b[34me2 7d \u001b[39;49;00m               \t\u001b[32mloop\u001b[39;49;00m   \u001b[34mea\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0xea\u001b[39;49;00m>\n",
      "  6d:\t\u001b[34m18 d0 \u001b[39;49;00m               \t\u001b[32msbb\u001b[39;49;00m    \u001b[31m%dl\u001b[39;49;00m,\u001b[31m%al\u001b[39;49;00m\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  6f:\t\u001b[34m48 63 f2 \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%rsi\u001b[39;49;00m\n",
      "    a[i] = a[i] * b + c;\n",
      "  72:\t\u001b[34mc5 fc 10 24 81 \u001b[39;49;00m      \t\u001b[32mvmovups\u001b[39;49;00m (\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m),\u001b[31m%ymm4\u001b[39;49;00m\n",
      "  77:\t\u001b[34mc5 fc 10 6c 81 20 \u001b[39;49;00m   \t\u001b[32mvmovups\u001b[39;49;00m \u001b[34m0x20\u001b[39;49;00m(\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m),\u001b[31m%ymm5\u001b[39;49;00m\n",
      "  7d:\t\u001b[34mc4 e2 6d a8 e3 \u001b[39;49;00m      \t\u001b[32mvfmadd213ps\u001b[39;49;00m \u001b[31m%ymm3\u001b[39;49;00m,\u001b[31m%ymm2\u001b[39;49;00m,\u001b[31m%ymm4\u001b[39;49;00m\n",
      "  82:\t\u001b[34mc4 e2 6d a8 eb \u001b[39;49;00m      \t\u001b[32mvfmadd213ps\u001b[39;49;00m \u001b[31m%ymm3\u001b[39;49;00m,\u001b[31m%ymm2\u001b[39;49;00m,\u001b[31m%ymm5\u001b[39;49;00m\n",
      "  87:\t\u001b[34mc5 fc 11 24 81 \u001b[39;49;00m      \t\u001b[32mvmovups\u001b[39;49;00m \u001b[31m%ymm4\u001b[39;49;00m,(\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m)\n",
      "  8c:\t\u001b[34mc5 fc 11 6c 81 20 \u001b[39;49;00m   \t\u001b[32mvmovups\u001b[39;49;00m \u001b[31m%ymm5\u001b[39;49;00m,\u001b[34m0x20\u001b[39;49;00m(\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m)\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  92:\t\u001b[34m48 83 c0 10 \u001b[39;49;00m         \t\u001b[32madd\u001b[39;49;00m    \u001b[31m$0x10\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  96:\t\u001b[34m48 3b c6 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%rsi\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  99:\t\u001b[34m72 d7 \u001b[39;49;00m               \t\u001b[32mjb\u001b[39;49;00m     \u001b[34m72\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x72\u001b[39;49;00m>\n",
      "  9b:\t\u001b[34m8d 42 01 \u001b[39;49;00m            \t\u001b[32mlea\u001b[39;49;00m    \u001b[34m0x1\u001b[39;49;00m(\u001b[31m%rdx\u001b[39;49;00m),\u001b[31m%eax\u001b[39;49;00m\n",
      "  9e:\t\u001b[34m3b f8 \u001b[39;49;00m               \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%eax\u001b[39;49;00m,\u001b[31m%edi\u001b[39;49;00m\n",
      "  a0:\t\u001b[34m72 6e \u001b[39;49;00m               \t\u001b[32mjb\u001b[39;49;00m     \u001b[34m110\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x110\u001b[39;49;00m>\n",
      "  a2:\t\u001b[34m48 63 ff \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%edi\u001b[39;49;00m,\u001b[31m%rdi\u001b[39;49;00m\n",
      "  a5:\t\u001b[34m48 63 d2 \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m\n",
      "  a8:\t\u001b[34m48 2b fa \u001b[39;49;00m            \t\u001b[32msub\u001b[39;49;00m    \u001b[31m%rdx\u001b[39;49;00m,\u001b[31m%rdi\u001b[39;49;00m\n",
      "  ab:\t\u001b[34m48 83 ff 04 \u001b[39;49;00m         \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m$0x4\u001b[39;49;00m,\u001b[31m%rdi\u001b[39;49;00m\n",
      "  af:\t\u001b[34m7c 63 \u001b[39;49;00m               \t\u001b[32mjl\u001b[39;49;00m     \u001b[34m114\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x114\u001b[39;49;00m>\n",
      "    a[i] = a[i] * b + c;\n",
      "  b1:\t\u001b[34m48 63 d2 \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  b4:\t\u001b[34m89 f8 \u001b[39;49;00m               \t\u001b[32mmov\u001b[39;49;00m    \u001b[31m%edi\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      "  b6:\t\u001b[34m83 e0 fc \u001b[39;49;00m            \t\u001b[32mand\u001b[39;49;00m    \u001b[31m$0xfffffffffffffffc\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      "  b9:\t\u001b[34m45 33 c0 \u001b[39;49;00m            \t\u001b[32mxor\u001b[39;49;00m    \u001b[31m%r8d\u001b[39;49;00m,\u001b[31m%r8d\u001b[39;49;00m\n",
      "  bc:\t\u001b[34m48 63 c0 \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%eax\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      " *\n",
      " * Input-Outputs:\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "  bf:\t\u001b[34mc4 e2 79 18 \u001b[39;49;00m         \u001b[33m\t(bad)  \u001b[39;49;00m\n",
      "  c3:\t\u001b[34md9 c4 \u001b[39;49;00m               \t\u001b[32mfld\u001b[39;49;00m    \u001b[31m%st\u001b[39;49;00m(\u001b[34m4\u001b[39;49;00m)\n",
      "  c5:\t\u001b[34me2 79 \u001b[39;49;00m               \t\u001b[32mloop\u001b[39;49;00m   \u001b[34m140\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x140\u001b[39;49;00m>\n",
      "  c7:\t\u001b[34m18 d0 \u001b[39;49;00m               \t\u001b[32msbb\u001b[39;49;00m    \u001b[31m%dl\u001b[39;49;00m,\u001b[31m%al\u001b[39;49;00m\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "    a[i] = a[i] * b + c;\n",
      "  c9:\t\u001b[34m48 8d 34 91 \u001b[39;49;00m         \t\u001b[32mlea\u001b[39;49;00m    (\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m),\u001b[31m%rsi\u001b[39;49;00m\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  cd:\t\u001b[34m49 83 c0 04 \u001b[39;49;00m         \t\u001b[32madd\u001b[39;49;00m    \u001b[31m$0x4\u001b[39;49;00m,\u001b[31m%r8\u001b[39;49;00m\n",
      "    a[i] = a[i] * b + c;\n",
      "  d1:\t\u001b[34mc5 f8 10 26 \u001b[39;49;00m         \t\u001b[32mvmovups\u001b[39;49;00m (\u001b[31m%rsi\u001b[39;49;00m),\u001b[31m%xmm4\u001b[39;49;00m\n",
      "  d5:\t\u001b[34mc4 e2 69 a8 e3 \u001b[39;49;00m      \t\u001b[32mvfmadd213ps\u001b[39;49;00m \u001b[31m%xmm3\u001b[39;49;00m,\u001b[31m%xmm2\u001b[39;49;00m,\u001b[31m%xmm4\u001b[39;49;00m\n",
      "  da:\t\u001b[34mc5 f8 11 26 \u001b[39;49;00m         \t\u001b[32mvmovups\u001b[39;49;00m \u001b[31m%xmm4\u001b[39;49;00m,(\u001b[31m%rsi\u001b[39;49;00m)\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  de:\t\u001b[34m48 83 c6 10 \u001b[39;49;00m         \t\u001b[32madd\u001b[39;49;00m    \u001b[31m$0x10\u001b[39;49;00m,\u001b[31m%rsi\u001b[39;49;00m\n",
      "  e2:\t\u001b[34m4c 3b c0 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%rax\u001b[39;49;00m,\u001b[31m%r8\u001b[39;49;00m\n",
      "  e5:\t\u001b[34m72 e6 \u001b[39;49;00m               \t\u001b[32mjb\u001b[39;49;00m     \u001b[34mcd\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0xcd\u001b[39;49;00m>\n",
      "  e7:\t\u001b[34m48 3b c7 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%rdi\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      "  ea:\t\u001b[34m73 24 \u001b[39;49;00m               \t\u001b[32mjae\u001b[39;49;00m    \u001b[34m110\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x110\u001b[39;49;00m>\n",
      "    a[i] = a[i] * b + c;\n",
      "  ec:\t\u001b[34m48 63 d2 \u001b[39;49;00m            \t\u001b[32mmovslq\u001b[39;49;00m \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m\n",
      "  ef:\t\u001b[34m48 8d 0c 91 \u001b[39;49;00m         \t\u001b[32mlea\u001b[39;49;00m    (\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m),\u001b[31m%rcx\u001b[39;49;00m\n",
      "  f3:\t\u001b[34m48 8d 14 81 \u001b[39;49;00m         \t\u001b[32mlea\u001b[39;49;00m    (\u001b[31m%rcx\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m,\u001b[34m4\u001b[39;49;00m),\u001b[31m%rdx\u001b[39;49;00m\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      "  f7:\t\u001b[34m48 ff c0 \u001b[39;49;00m            \t\u001b[32minc\u001b[39;49;00m    \u001b[31m%rax\u001b[39;49;00m\n",
      "    a[i] = a[i] * b + c;\n",
      "  fa:\t\u001b[34mc5 fa 10 12 \u001b[39;49;00m         \t\u001b[32mvmovss\u001b[39;49;00m (\u001b[31m%rdx\u001b[39;49;00m),\u001b[31m%xmm2\u001b[39;49;00m\n",
      "  fe:\t\u001b[34mc4 e2 79 a9 d1 \u001b[39;49;00m      \t\u001b[32mvfmadd213ss\u001b[39;49;00m \u001b[31m%xmm1\u001b[39;49;00m,\u001b[31m%xmm0\u001b[39;49;00m,\u001b[31m%xmm2\u001b[39;49;00m\n",
      " 103:\t\u001b[34mc5 fa 11 12 \u001b[39;49;00m         \t\u001b[32mvmovss\u001b[39;49;00m \u001b[31m%xmm2\u001b[39;49;00m,(\u001b[31m%rdx\u001b[39;49;00m)\n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      " 107:\t\u001b[34m48 83 c2 04 \u001b[39;49;00m         \t\u001b[32madd\u001b[39;49;00m    \u001b[31m$0x4\u001b[39;49;00m,\u001b[31m%rdx\u001b[39;49;00m\n",
      " 10b:\t\u001b[34m48 3b c7 \u001b[39;49;00m            \t\u001b[32mcmp\u001b[39;49;00m    \u001b[31m%rdi\u001b[39;49;00m,\u001b[31m%rax\u001b[39;49;00m\n",
      " 10e:\t\u001b[34m72 e7 \u001b[39;49;00m               \t\u001b[32mjb\u001b[39;49;00m     \u001b[34mf7\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0xf7\u001b[39;49;00m>\n",
      "    a[i] = a[i] * b + c;\n",
      "  }\n",
      "}\n",
      " 110:\t\u001b[34mc5 f8 77 \u001b[39;49;00m            \t\u001b[32mvzeroupper\u001b[39;49;00m \n",
      " 113:\t\u001b[34mc3 \u001b[39;49;00m                  \t\u001b[32mretq\u001b[39;49;00m   \n",
      " * a : the array\n",
      " \u001b[04m\u001b[31;01m*/\u001b[39;49;00m\n",
      "\u001b[36mvoid\u001b[39;49;00m\n",
      "fma_loop_short (\u001b[36mint\u001b[39;49;00m N, \u001b[36mint\u001b[39;49;00m T, \u001b[36mfloat\u001b[39;49;00m *a, \u001b[36mfloat\u001b[39;49;00m b, \u001b[36mfloat\u001b[39;49;00m c)\n",
      "{\n",
      "  \u001b[34mfor\u001b[39;49;00m (\u001b[36mint\u001b[39;49;00m i = \u001b[34m0\u001b[39;49;00m; i < N; i++) {\n",
      " 114:\t\u001b[34m33 c0 \u001b[39;49;00m               \t\u001b[32mxor\u001b[39;49;00m    \u001b[31m%eax\u001b[39;49;00m,\u001b[31m%eax\u001b[39;49;00m\n",
      " 116:\t\u001b[34meb cf \u001b[39;49;00m               \t\u001b[32mjmp\u001b[39;49;00m    \u001b[34me7\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0xe7\u001b[39;49;00m>\n",
      " 118:\t\u001b[34m33 d2 \u001b[39;49;00m               \t\u001b[32mxor\u001b[39;49;00m    \u001b[31m%edx\u001b[39;49;00m,\u001b[31m%edx\u001b[39;49;00m\n",
      " 11a:\t\u001b[34me9 7c ff ff ff \u001b[39;49;00m      \t\u001b[32mjmpq\u001b[39;49;00m   \u001b[34m9b\u001b[39;49;00m <\u001b[31mfma_loop_short\u001b[39;49;00m+\u001b[34m0x9b\u001b[39;49;00m>\n",
      " 11f:\t\u001b[34m90 \u001b[39;49;00m                  \t\u001b[32mnop\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "objdump -Sd fma_loop_short.o | pygmentize -l c-objdump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compiler actually compiled several version of the loop, some optimized for different inputs.\n",
    "\n",
    "There are instructions that we didnt see before, like `vfmadd213ss`.  Let's go to Intel's [intrinsics reference](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#!=undefined) to see what we can see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we learn:\n",
    "\n",
    "- There are **vectorized** instructions, when a single instruction operates on multiple data at one time (SIMD).\n",
    "- **Fused multiply add** is an instruction that counts as two flops at once!  It is so fundamental to linear algebra that it deserves optimization.\n",
    "- **Execution itself is pipelined**, with the pipeline depth depending on the instruction.\n",
    "- Sometimes there are multiple functional units that can do the same instruction (2 FPUs on a modern Intel chip, for instance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "Because pipelined instructions have to be independent, how many independent FMAs do we need in order to issue one per cycle to each FPU on a core, thus achieving peak flops/cycle?\n",
    "\n",
    "An application of\n",
    "\n",
    "## Little's Law\n",
    "\n",
    "$$\\Huge L = \\lambda W$$\n",
    "\n",
    "- $L$: The concurrency, number of concurrent, independent operations that will fill the pipeline\n",
    "- $\\lambda$: the \"width\" of the data that can be entered into the pipeline in a single cycle\n",
    "- $W$: the depth of the pipeline\n",
    "\n",
    "Let's do this for our setup:\n",
    "\n",
    "- $W$: the pipeline depth.  Get this from the manufacturer for your chip (if you can).  E.g. for an Intel Broadwell chip, the pipeline depth of `vfmadd*ps` instructions is 5.\n",
    "- $\\lambda$: the width of the data.  Each vector FMA operation works on 8 sets of operands, and there are 2 functional units that can execute the command, so $\\lambda = 8 * 2 = 16$.\n",
    "- Therefore I need $5 * 16 = 80$ independent FMA operations to fill the pipeline.\n",
    "- Another way to think of it: if my algorithm is composed mostly of FMAs, and it can be rewritten to be more concurrent, I expect to see a speedup up until about 80-way concurrency, and no benefit beyond that.  If my algorithm has less that 80-way concurrency, there will be bubbles in the FMA pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what is the peak flop/s per CPU core?\n",
    "\n",
    "Assuming that all floating point units (FPUs) can compute FMAs, and that each can be issued an FMA concurrently due to superscalarity,\n",
    "\n",
    "$$P_{\\text{core}} = \\#\\text{FPUs} * \\text{vector width (FMAs / FPU)} * 2 \\text{ (flops / FMA)} * \\text{throughput (1 / cycle)} * \\text{clock rate (cycles / sec)}$$\n",
    "\n",
    "So, putting in the numbers for my computer,\n",
    "\n",
    "$$P_{\\text{core}} = 2 \\text{ FPUs} * 8 \\text{ FMAs / FPU} * 2 \\text{ flops / FMA} * \\text{1 / cycle} * 3.1 \\text{ (Gigacycles / sec)} = 99.2\\text{ Gigaflop/s.}$$\n",
    "\n",
    "I have two cores, meaning $P_{\\text{total}} = 198.4$ Gigaflop/s, what we calculated in the first lecture, hooray!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing CPU cores and GPU streaming multiprocessors (SMs)\n",
    "\n",
    "Here is a link to Prof. Vuduc's Intro to GPUs and CUDA [slides](http://vuduc.org/cse6230/slides/cse6230-fa14--05-cuda.pdf).\n",
    "\n",
    "Relevant to today's discussion:\n",
    "\n",
    "- Slides 19-24 on the execution model\n",
    "- Slides 48-51 on performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key takeaways:\n",
    "\n",
    "- The CUDA programming model is Single Instruction Mutliple Thread: each thread has its own registers, but a shared instruction stream.\n",
    "- One instruction is executed on a **warp** a group of 32 threads that mostly work in lock step\n",
    "- Every instruction is vectorized, not just special instructions on the CPU.\n",
    "- Mostly: any branch divergence between them is *serialized*, so in addition to misprediction, branching has another steep price on GPUs.\n",
    "- Question: what are the depths of the pipelines on a Streaming Multiprocessor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are relevant diagrams of NVIDIA streaming multiprocessors:\n",
    "\n",
    "![SMs](./images/nvidia-kepler-vs-maxwell-sm.gif)\n",
    "\n",
    "- Every functional unit that is listed as a core handles integer and single precision floating point operations.  Double precision operations are handled by separate units, of which there are some in Kepler (1 for every 3 single precision), and few in Maxwell (1 for every 32 single precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table from NVIDIA's white paper for the Pascal architecture:\n",
    "\n",
    "![NVIDIA Table 1](./images/nvidia-table.png)\n",
    "\n",
    "Can you figure how the double and single precision flop/s are computed?\n",
    "\n",
    "- They are counting FMAs\n",
    "- Each core is a non-vectorized FPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploiting The Concurrency In Your Code\n",
    "\n",
    "Here is a link to Prof. Vuduc's GPU Performance Tuning [slides](http://vuduc.org/cse6230/slides/cse6230-fa14--07-gpu-tuning-1.pdf)\n",
    "\n",
    "- Relevant to today (and to your second assignment) are slides 27-40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: given all this pipelining, how can I predict the throughput of my kernel?\n",
    "\n",
    "The answer I gave in class was, that we could find the critical path through the directed acyclic graph of computations.  Something like this from [wikipedia](https://en.wikipedia.org/wiki/Directed_acyclic_graph#/media/File:Pert_chart_colored.svg), but with pipeline depth instead of months.\n",
    "\n",
    "![dag](./images/Pert_chart_colored.svg)\n",
    "\n",
    "The experts in this type of thing say that this type of analysis is easier said that done: see Section 3.2 of this recent work from [Hoffman et al.](https://arxiv.org/pdf/1702.07554.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
